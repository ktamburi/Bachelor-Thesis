{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install matplotlib\n",
        "%pip install scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: matplotlib in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.10.3)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (4.58.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.23 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.2.5)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (3.2.3)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: scikit-learn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.6.1)\nRequirement already satisfied: numpy>=1.19.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (2.2.5)\nRequirement already satisfied: scipy>=1.6.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: seaborn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.20 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from seaborn) (2.2.5)\nRequirement already satisfied: pandas>=1.2 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.4 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from seaborn) (3.10.3)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1749268449714
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_eda(df):\n",
        "    print(df)\n",
        "    print(\"----------------------------------INFO-----------------------------------------\")\n",
        "    print(df.info())\n",
        "    print(\"----------------------------------Columns--------------------------------------\")\n",
        "    print(df.columns)\n",
        "    print(\"----------------------------------Data Types-----------------------------------\")\n",
        "    print(df.dtypes)\n",
        "    print(\"-------------------------------Missing Values----------------------------------\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"-------------------------------NULL values-------------------------------------\")\n",
        "    print(df.isna().sum())\n",
        "    print(\"------------------------------Shape Of Data------------------------------------\")\n",
        "    print(df.shape)\n",
        "    print(\"-------------------------Unique values per categorical column-------------------\")\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in cat_cols:\n",
        "        print(f\"\\nColumn '{col}' unique values:\")\n",
        "        print(df[col].unique())\n",
        "    print(\"=============================================================================== \\n\")\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1749080928005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "\n",
        "test = pd.read_csv(\"test.csv\", low_memory=False)\n",
        "test['date'] = pd.to_datetime(test['date'])\n",
        "\n",
        "stores = pd.read_csv(\"stores.csv\")\n",
        "\n",
        "items = pd.read_csv('items.csv')\n",
        "\n",
        "holidays_events = pd.read_csv(\"holidays_events.csv\")\n",
        "holidays_events['date'] = pd.to_datetime(holidays_events['date'])\n",
        "\n",
        "transactions = pd.read_csv(\"transactions.csv\")\n",
        "transactions['date'] = pd.to_datetime(transactions['date'])\n",
        "\n",
        "oil = pd.read_csv(\"oil.csv\")\n",
        "oil['date'] = pd.to_datetime(oil['date'])"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpDgk5FbmIu_",
        "outputId": "5ad9b781-bd12-4cc2-f3ae-f1f6dfa9c82e",
        "gather": {
          "logged": 1749081060552
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"====================================Train Data====================================\")\n",
        "basic_eda(train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "====================================Train Data====================================\n                  id       date  store_nbr  item_nbr  unit_sales onpromotion\n0                  0 2013-01-01         25    103665         7.0         NaN\n1                  1 2013-01-01         25    105574         1.0         NaN\n2                  2 2013-01-01         25    105575         2.0         NaN\n3                  3 2013-01-01         25    108079         1.0         NaN\n4                  4 2013-01-01         25    108701         1.0         NaN\n...              ...        ...        ...       ...         ...         ...\n125497035  125497035 2017-08-15         54   2089339         4.0       False\n125497036  125497036 2017-08-15         54   2106464         1.0        True\n125497037  125497037 2017-08-15         54   2110456       192.0       False\n125497038  125497038 2017-08-15         54   2113914       198.0        True\n125497039  125497039 2017-08-15         54   2116416         2.0       False\n\n[125497040 rows x 6 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 125497040 entries, 0 to 125497039\nData columns (total 6 columns):\n #   Column       Dtype         \n---  ------       -----         \n 0   id           int64         \n 1   date         datetime64[ns]\n 2   store_nbr    int64         \n 3   item_nbr     int64         \n 4   unit_sales   float64       \n 5   onpromotion  object        \ndtypes: datetime64[ns](1), float64(1), int64(3), object(1)\nmemory usage: 5.6+ GB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion'], dtype='object')\n----------------------------------Data Types-----------------------------------\nid                      int64\ndate           datetime64[ns]\nstore_nbr               int64\nitem_nbr                int64\nunit_sales            float64\nonpromotion            object\ndtype: object\n-------------------------------Missing Values----------------------------------\nid                    0\ndate                  0\nstore_nbr             0\nitem_nbr              0\nunit_sales            0\nonpromotion    21657651\ndtype: int64\n-------------------------------NULL values-------------------------------------\nid                    0\ndate                  0\nstore_nbr             0\nitem_nbr              0\nunit_sales            0\nonpromotion    21657651\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(125497040, 6)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'onpromotion' unique values:\n[nan False True]\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1749081076937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"====================================Test Data====================================\")\n",
        "basic_eda(test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "====================================Test Data====================================\n                id       date  store_nbr  item_nbr  onpromotion\n0        125497040 2017-08-16          1     96995        False\n1        125497041 2017-08-16          1     99197        False\n2        125497042 2017-08-16          1    103501        False\n3        125497043 2017-08-16          1    103520        False\n4        125497044 2017-08-16          1    103665        False\n...            ...        ...        ...       ...          ...\n3370459  128867499 2017-08-31         54   2132163        False\n3370460  128867500 2017-08-31         54   2132318        False\n3370461  128867501 2017-08-31         54   2132945        False\n3370462  128867502 2017-08-31         54   2132957        False\n3370463  128867503 2017-08-31         54   2134244        False\n\n[3370464 rows x 5 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3370464 entries, 0 to 3370463\nData columns (total 5 columns):\n #   Column       Dtype         \n---  ------       -----         \n 0   id           int64         \n 1   date         datetime64[ns]\n 2   store_nbr    int64         \n 3   item_nbr     int64         \n 4   onpromotion  bool          \ndtypes: bool(1), datetime64[ns](1), int64(3)\nmemory usage: 106.1 MB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['id', 'date', 'store_nbr', 'item_nbr', 'onpromotion'], dtype='object')\n----------------------------------Data Types-----------------------------------\nid                      int64\ndate           datetime64[ns]\nstore_nbr               int64\nitem_nbr                int64\nonpromotion              bool\ndtype: object\n-------------------------------Missing Values----------------------------------\nid             0\ndate           0\nstore_nbr      0\nitem_nbr       0\nonpromotion    0\ndtype: int64\n-------------------------------NULL values-------------------------------------\nid             0\ndate           0\nstore_nbr      0\nitem_nbr       0\nonpromotion    0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(3370464, 5)\n-------------------------Unique values per categorical column-------------------\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1749081077118
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"=================================Holidays events==================================\")\n",
        "basic_eda(holidays_events)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "=================================Holidays events==================================\n          date        type    locale locale_name  \\\n0   2012-03-02     Holiday     Local       Manta   \n1   2012-04-01     Holiday  Regional    Cotopaxi   \n2   2012-04-12     Holiday     Local      Cuenca   \n3   2012-04-14     Holiday     Local    Libertad   \n4   2012-04-21     Holiday     Local    Riobamba   \n..         ...         ...       ...         ...   \n345 2017-12-22  Additional  National     Ecuador   \n346 2017-12-23  Additional  National     Ecuador   \n347 2017-12-24  Additional  National     Ecuador   \n348 2017-12-25     Holiday  National     Ecuador   \n349 2017-12-26  Additional  National     Ecuador   \n\n                       description  transferred  \n0               Fundacion de Manta        False  \n1    Provincializacion de Cotopaxi        False  \n2              Fundacion de Cuenca        False  \n3        Cantonizacion de Libertad        False  \n4        Cantonizacion de Riobamba        False  \n..                             ...          ...  \n345                      Navidad-3        False  \n346                      Navidad-2        False  \n347                      Navidad-1        False  \n348                        Navidad        False  \n349                      Navidad+1        False  \n\n[350 rows x 6 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 350 entries, 0 to 349\nData columns (total 6 columns):\n #   Column       Non-Null Count  Dtype         \n---  ------       --------------  -----         \n 0   date         350 non-null    datetime64[ns]\n 1   type         350 non-null    object        \n 2   locale       350 non-null    object        \n 3   locale_name  350 non-null    object        \n 4   description  350 non-null    object        \n 5   transferred  350 non-null    bool          \ndtypes: bool(1), datetime64[ns](1), object(4)\nmemory usage: 14.1+ KB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['date', 'type', 'locale', 'locale_name', 'description', 'transferred'], dtype='object')\n----------------------------------Data Types-----------------------------------\ndate           datetime64[ns]\ntype                   object\nlocale                 object\nlocale_name            object\ndescription            object\ntransferred              bool\ndtype: object\n-------------------------------Missing Values----------------------------------\ndate           0\ntype           0\nlocale         0\nlocale_name    0\ndescription    0\ntransferred    0\ndtype: int64\n-------------------------------NULL values-------------------------------------\ndate           0\ntype           0\nlocale         0\nlocale_name    0\ndescription    0\ntransferred    0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(350, 6)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'type' unique values:\n['Holiday' 'Transfer' 'Additional' 'Bridge' 'Work Day' 'Event']\n\nColumn 'locale' unique values:\n['Local' 'Regional' 'National']\n\nColumn 'locale_name' unique values:\n['Manta' 'Cotopaxi' 'Cuenca' 'Libertad' 'Riobamba' 'Puyo' 'Guaranda'\n 'Imbabura' 'Latacunga' 'Machala' 'Santo Domingo' 'El Carmen' 'Cayambe'\n 'Esmeraldas' 'Ecuador' 'Ambato' 'Ibarra' 'Quevedo'\n 'Santo Domingo de los Tsachilas' 'Santa Elena' 'Quito' 'Loja' 'Salinas'\n 'Guayaquil']\n\nColumn 'description' unique values:\n['Fundacion de Manta' 'Provincializacion de Cotopaxi'\n 'Fundacion de Cuenca' 'Cantonizacion de Libertad'\n 'Cantonizacion de Riobamba' 'Cantonizacion del Puyo'\n 'Cantonizacion de Guaranda' 'Provincializacion de Imbabura'\n 'Cantonizacion de Latacunga' 'Fundacion de Machala'\n 'Fundacion de Santo Domingo' 'Cantonizacion de El Carmen'\n 'Cantonizacion de Cayambe' 'Fundacion de Esmeraldas'\n 'Primer Grito de Independencia' 'Fundacion de Riobamba'\n 'Fundacion de Ambato' 'Fundacion de Ibarra' 'Cantonizacion de Quevedo'\n 'Independencia de Guayaquil' 'Traslado Independencia de Guayaquil'\n 'Dia de Difuntos' 'Independencia de Cuenca'\n 'Provincializacion de Santo Domingo' 'Provincializacion Santa Elena'\n 'Independencia de Guaranda' 'Independencia de Latacunga'\n 'Independencia de Ambato' 'Fundacion de Quito-1' 'Fundacion de Quito'\n 'Fundacion de Loja' 'Navidad-4' 'Cantonizacion de Salinas' 'Navidad-3'\n 'Navidad-2' 'Puente Navidad' 'Navidad-1' 'Navidad' 'Navidad+1'\n 'Puente Primer dia del ano' 'Primer dia del ano-1' 'Primer dia del ano'\n 'Recupero puente Navidad' 'Recupero puente primer dia del ano' 'Carnaval'\n 'Viernes Santo' 'Dia del Trabajo' 'Dia de la Madre-1' 'Dia de la Madre'\n 'Batalla de Pichincha' 'Fundacion de Guayaquil-1'\n 'Fundacion de Guayaquil' 'Inauguracion Mundial de futbol Brasil'\n 'Mundial de futbol Brasil: Ecuador-Suiza'\n 'Mundial de futbol Brasil: Ecuador-Honduras'\n 'Mundial de futbol Brasil: Ecuador-Francia'\n 'Mundial de futbol Brasil: Octavos de Final'\n 'Mundial de futbol Brasil: Cuartos de Final'\n 'Mundial de futbol Brasil: Semifinales'\n 'Mundial de futbol Brasil: Tercer y cuarto lugar'\n 'Mundial de futbol Brasil: Final' 'Black Friday' 'Cyber Monday'\n 'Recupero Puente Navidad' 'Recupero Puente Primer dia del ano'\n 'Terremoto Manabi' 'Terremoto Manabi+1' 'Terremoto Manabi+2'\n 'Terremoto Manabi+3' 'Terremoto Manabi+4' 'Terremoto Manabi+5'\n 'Terremoto Manabi+6' 'Terremoto Manabi+7' 'Terremoto Manabi+8'\n 'Terremoto Manabi+9' 'Terremoto Manabi+10' 'Terremoto Manabi+11'\n 'Terremoto Manabi+12' 'Terremoto Manabi+13' 'Terremoto Manabi+14'\n 'Terremoto Manabi+15' 'Terremoto Manabi+16' 'Terremoto Manabi+17'\n 'Terremoto Manabi+18' 'Terremoto Manabi+19' 'Terremoto Manabi+20'\n 'Terremoto Manabi+21' 'Terremoto Manabi+22' 'Terremoto Manabi+23'\n 'Terremoto Manabi+24' 'Terremoto Manabi+25' 'Terremoto Manabi+26'\n 'Terremoto Manabi+27' 'Terremoto Manabi+28' 'Terremoto Manabi+29'\n 'Terremoto Manabi+30' 'Traslado Batalla de Pichincha'\n 'Traslado Fundacion de Guayaquil'\n 'Traslado Primer Grito de Independencia' 'Puente Dia de Difuntos'\n 'Recupero Puente Dia de Difuntos' 'Traslado Primer dia del ano'\n 'Traslado Fundacion de Quito']\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1749081077288
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"================================Transactions data=================================\")\n",
        "basic_eda(transactions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "================================Transactions data=================================\n            date  store_nbr  transactions\n0     2013-01-01         25           770\n1     2013-01-02          1          2111\n2     2013-01-02          2          2358\n3     2013-01-02          3          3487\n4     2013-01-02          4          1922\n...          ...        ...           ...\n83483 2017-08-15         50          2804\n83484 2017-08-15         51          1573\n83485 2017-08-15         52          2255\n83486 2017-08-15         53           932\n83487 2017-08-15         54           802\n\n[83488 rows x 3 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 83488 entries, 0 to 83487\nData columns (total 3 columns):\n #   Column        Non-Null Count  Dtype         \n---  ------        --------------  -----         \n 0   date          83488 non-null  datetime64[ns]\n 1   store_nbr     83488 non-null  int64         \n 2   transactions  83488 non-null  int64         \ndtypes: datetime64[ns](1), int64(2)\nmemory usage: 1.9 MB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['date', 'store_nbr', 'transactions'], dtype='object')\n----------------------------------Data Types-----------------------------------\ndate            datetime64[ns]\nstore_nbr                int64\ntransactions             int64\ndtype: object\n-------------------------------Missing Values----------------------------------\ndate            0\nstore_nbr       0\ntransactions    0\ndtype: int64\n-------------------------------NULL values-------------------------------------\ndate            0\nstore_nbr       0\ntransactions    0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(83488, 3)\n-------------------------Unique values per categorical column-------------------\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1749081077450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"===================================Stores data====================================\")\n",
        "basic_eda(stores)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "===================================Stores data====================================\n    store_nbr           city                           state type  cluster\n0           1          Quito                       Pichincha    D       13\n1           2          Quito                       Pichincha    D       13\n2           3          Quito                       Pichincha    D        8\n3           4          Quito                       Pichincha    D        9\n4           5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n5           6          Quito                       Pichincha    D       13\n6           7          Quito                       Pichincha    D        8\n7           8          Quito                       Pichincha    D        8\n8           9          Quito                       Pichincha    B        6\n9          10          Quito                       Pichincha    C       15\n10         11        Cayambe                       Pichincha    B        6\n11         12      Latacunga                        Cotopaxi    C       15\n12         13      Latacunga                        Cotopaxi    C       15\n13         14       Riobamba                      Chimborazo    C        7\n14         15         Ibarra                        Imbabura    C       15\n15         16  Santo Domingo  Santo Domingo de los Tsachilas    C        3\n16         17          Quito                       Pichincha    C       12\n17         18          Quito                       Pichincha    B       16\n18         19       Guaranda                         Bolivar    C       15\n19         20          Quito                       Pichincha    B        6\n20         21  Santo Domingo  Santo Domingo de los Tsachilas    B        6\n21         22           Puyo                         Pastaza    C        7\n22         23         Ambato                      Tungurahua    D        9\n23         24      Guayaquil                          Guayas    D        1\n24         25        Salinas                     Santa Elena    D        1\n25         26      Guayaquil                          Guayas    D       10\n26         27          Daule                          Guayas    D        1\n27         28      Guayaquil                          Guayas    E       10\n28         29      Guayaquil                          Guayas    E       10\n29         30      Guayaquil                          Guayas    C        3\n30         31       Babahoyo                        Los Rios    B       10\n31         32      Guayaquil                          Guayas    C        3\n32         33        Quevedo                        Los Rios    C        3\n33         34      Guayaquil                          Guayas    B        6\n34         35         Playas                          Guayas    C        3\n35         36       Libertad                          Guayas    E       10\n36         37         Cuenca                           Azuay    D        2\n37         38           Loja                            Loja    D        4\n38         39         Cuenca                           Azuay    B        6\n39         40        Machala                          El Oro    C        3\n40         41        Machala                          El Oro    D        4\n41         42         Cuenca                           Azuay    D        2\n42         43     Esmeraldas                      Esmeraldas    E       10\n43         44          Quito                       Pichincha    A        5\n44         45          Quito                       Pichincha    A       11\n45         46          Quito                       Pichincha    A       14\n46         47          Quito                       Pichincha    A       14\n47         48          Quito                       Pichincha    A       14\n48         49          Quito                       Pichincha    A       11\n49         50         Ambato                      Tungurahua    A       14\n50         51      Guayaquil                          Guayas    A       17\n51         52          Manta                          Manabi    A       11\n52         53          Manta                          Manabi    D       13\n53         54      El Carmen                          Manabi    C        3\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 54 entries, 0 to 53\nData columns (total 5 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   store_nbr  54 non-null     int64 \n 1   city       54 non-null     object\n 2   state      54 non-null     object\n 3   type       54 non-null     object\n 4   cluster    54 non-null     int64 \ndtypes: int64(2), object(3)\nmemory usage: 2.2+ KB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['store_nbr', 'city', 'state', 'type', 'cluster'], dtype='object')\n----------------------------------Data Types-----------------------------------\nstore_nbr     int64\ncity         object\nstate        object\ntype         object\ncluster       int64\ndtype: object\n-------------------------------Missing Values----------------------------------\nstore_nbr    0\ncity         0\nstate        0\ntype         0\ncluster      0\ndtype: int64\n-------------------------------NULL values-------------------------------------\nstore_nbr    0\ncity         0\nstate        0\ntype         0\ncluster      0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(54, 5)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'city' unique values:\n['Quito' 'Santo Domingo' 'Cayambe' 'Latacunga' 'Riobamba' 'Ibarra'\n 'Guaranda' 'Puyo' 'Ambato' 'Guayaquil' 'Salinas' 'Daule' 'Babahoyo'\n 'Quevedo' 'Playas' 'Libertad' 'Cuenca' 'Loja' 'Machala' 'Esmeraldas'\n 'Manta' 'El Carmen']\n\nColumn 'state' unique values:\n['Pichincha' 'Santo Domingo de los Tsachilas' 'Cotopaxi' 'Chimborazo'\n 'Imbabura' 'Bolivar' 'Pastaza' 'Tungurahua' 'Guayas' 'Santa Elena'\n 'Los Rios' 'Azuay' 'Loja' 'El Oro' 'Esmeraldas' 'Manabi']\n\nColumn 'type' unique values:\n['D' 'B' 'C' 'E' 'A']\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1749081077610
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"=====================================Oil data=====================================\")\n",
        "basic_eda(oil)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "=====================================Oil data=====================================\n           date  dcoilwtico\n0    2013-01-01         NaN\n1    2013-01-02       93.14\n2    2013-01-03       92.97\n3    2013-01-04       93.12\n4    2013-01-07       93.20\n...         ...         ...\n1213 2017-08-25       47.65\n1214 2017-08-28       46.40\n1215 2017-08-29       46.46\n1216 2017-08-30       45.96\n1217 2017-08-31       47.26\n\n[1218 rows x 2 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1218 entries, 0 to 1217\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   date        1218 non-null   datetime64[ns]\n 1   dcoilwtico  1175 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 19.2 KB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['date', 'dcoilwtico'], dtype='object')\n----------------------------------Data Types-----------------------------------\ndate          datetime64[ns]\ndcoilwtico           float64\ndtype: object\n-------------------------------Missing Values----------------------------------\ndate           0\ndcoilwtico    43\ndtype: int64\n-------------------------------NULL values-------------------------------------\ndate           0\ndcoilwtico    43\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(1218, 2)\n-------------------------Unique values per categorical column-------------------\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1749081077768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"====================================Items Data====================================\")\n",
        "basic_eda(items)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "====================================Items Data====================================\n      item_nbr            family  class  perishable\n0        96995         GROCERY I   1093           0\n1        99197         GROCERY I   1067           0\n2       103501          CLEANING   3008           0\n3       103520         GROCERY I   1028           0\n4       103665      BREAD/BAKERY   2712           1\n...        ...               ...    ...         ...\n4095   2132318         GROCERY I   1002           0\n4096   2132945         GROCERY I   1026           0\n4097   2132957         GROCERY I   1068           0\n4098   2134058         BEVERAGES   1124           0\n4099   2134244  LIQUOR,WINE,BEER   1364           0\n\n[4100 rows x 4 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4100 entries, 0 to 4099\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   item_nbr    4100 non-null   int64 \n 1   family      4100 non-null   object\n 2   class       4100 non-null   int64 \n 3   perishable  4100 non-null   int64 \ndtypes: int64(3), object(1)\nmemory usage: 128.2+ KB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['item_nbr', 'family', 'class', 'perishable'], dtype='object')\n----------------------------------Data Types-----------------------------------\nitem_nbr       int64\nfamily        object\nclass          int64\nperishable     int64\ndtype: object\n-------------------------------Missing Values----------------------------------\nitem_nbr      0\nfamily        0\nclass         0\nperishable    0\ndtype: int64\n-------------------------------NULL values-------------------------------------\nitem_nbr      0\nfamily        0\nclass         0\nperishable    0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(4100, 4)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'family' unique values:\n['GROCERY I' 'CLEANING' 'BREAD/BAKERY' 'DELI' 'POULTRY' 'EGGS'\n 'PERSONAL CARE' 'LINGERIE' 'BEVERAGES' 'AUTOMOTIVE' 'DAIRY' 'GROCERY II'\n 'MEATS' 'FROZEN FOODS' 'HOME APPLIANCES' 'SEAFOOD' 'PREPARED FOODS'\n 'LIQUOR,WINE,BEER' 'BEAUTY' 'HARDWARE' 'LAWN AND GARDEN' 'PRODUCE'\n 'HOME AND KITCHEN II' 'HOME AND KITCHEN I' 'MAGAZINES' 'HOME CARE'\n 'PET SUPPLIES' 'BABY CARE' 'SCHOOL AND OFFICE SUPPLIES'\n 'PLAYERS AND ELECTRONICS' 'CELEBRATION' 'LADIESWEAR' 'BOOKS']\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1749081078017
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming columns for consistency\n",
        "train.rename(columns={'unit_sales': 'Sales', 'item_nbr': 'Product', 'store_nbr': 'Store', 'onpromotion': 'OnPromotion'}, inplace=True)\n",
        "\n",
        "test.rename(columns={ 'item_nbr': 'Product', 'store_nbr': 'Store', 'onpromotion': 'OnPromotion'}, inplace=True)\n",
        "\n",
        "stores.rename(columns={'store_nbr': 'Store', 'city':'City', 'state': 'State', 'type':'StoreType',  'cluster':'StoreCluster'}, inplace=True)\n",
        "\n",
        "transactions.rename(columns={'transactions':'Transactions', 'store_nbr':'Store'}, inplace=True)\n",
        "\n",
        "oil.rename(columns={\"dcoilwtico\": \"OilPrice\"}, inplace=True)\n",
        "\n",
        "items.rename(columns={'item_nbr':'Product', 'family':'ProductFamily', 'class':'ProductClass', 'perishable':'IsPerishable'}, inplace=True )"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1749081078170
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generated store capacity (in units) since missing and needed for use in stock optimization and product distribution\n",
        "store_capacities = [\n",
        "    2825000, 2825000, 2700000, 2725000, 260000, 2825000, 2700000, 2700000, 6360000, 1150000,\n",
        "    6360000, 1150000, 1150000, 1070000, 1150000, 1030000, 1120000, 6960000, 1150000, 6360000,\n",
        "    6360000, 1070000, 297500, 252500, 275000, 252500, 165000, 165000, 1030000, 6600000,\n",
        "    1030000, 1030000, 1030000, 6360000, 1030000, 255000, 260000, 6360000, 1030000, 260000,\n",
        "    255000, 255000, 165000, 12600000, 13320000, 13680000, 13680000, 13680000, 13320000, 13680000,\n",
        "    14040000, 13320000, 2825000, 1030000\n",
        "]\n",
        "\n",
        "stores['StoreCapacity'] = store_capacities"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1749266361862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the holidays with 'transferred' = true because they weren't celebrated on those days\n",
        "# (the dates are normal day) but on the days that say 'type' = transferred\n",
        "holidays = holidays_events.drop(holidays_events[holidays_events['transferred'] == True].index)\n",
        "holidays[\"IsHoliday\"] = 1\n",
        "holidays = holidays [[\"date\", \"IsHoliday\"]].drop_duplicates() # Drop dupe dates"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1749081078499
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a complete date range since some dates missing\n",
        "full_dates = pd.date_range(start=\"2013-01-01\", end=\"2017-08-31\")\n",
        "full_oil = pd.DataFrame({'date': full_dates})\n",
        "\n",
        "oil = pd.merge(full_oil, oil, on='date', how='left')\n",
        "\n",
        "oil.sort_values('date', inplace=True)\n",
        "oil.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Fill in null values\n",
        "oil[\"OilPrice\"] = oil[\"OilPrice\"].ffill().bfill() # added back filling since first date empty"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1749327121676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN with 'False' first and then map to 0 and 1\n",
        "train['OnPromotion'] = train['OnPromotion'].fillna(False).astype(bool).astype(int)\n",
        "test['OnPromotion'] = test['OnPromotion'].fillna(False).astype(bool).astype(int)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3051/1121891112.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train['OnPromotion'] = train['OnPromotion'].fillna(False).astype(bool).astype(int)\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1749081089080
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['OnPromotion'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "OnPromotion\n0    117686418\n1      7810622\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1749081089708
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['OnPromotion'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "OnPromotion\n0    3171867\n1     198597\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1749081089896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Min date from train set: %s' % train['date'].min().date())\n",
        "print('Max date from train set: %s' % train['date'].max().date())\n",
        "\n",
        "print('Min date from test set: %s' % test['date'].min().date())\n",
        "print('Max date from test set: %s' % test['date'].max().date())\n",
        "\n",
        "print('Min date from transaction set: %s' % transactions['date'].min().date())\n",
        "print('Max date from transaction set: %s' % transactions['date'].max().date())\n",
        "\n",
        "# Test dates are missing in transactions, since want to use transactions as input features for predicting sales\n",
        "# it is necessary to forecast transactions as well initially. Filling in these missing values ensures\n",
        "# the test dataset has realistic transaction data, preventing zeros or missing values from hurting sales prediction accuracy."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Min date from train set: 2013-01-01\nMax date from train set: 2017-08-15\nMin date from test set: 2017-08-16\nMax date from test set: 2017-08-31\nMin date from transaction set: 2013-01-01\nMax date from transaction set: 2017-08-15\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1749081090573
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge first with items to get product families and group products per store per date by product family\n",
        "train_merged = train.merge(items, on=\"Product\", how=\"left\")\n",
        "test_merged = test.merge(items, on=\"Product\", how=\"left\")\n",
        "\n",
        "# Group by date store product family to reduce dataset due to big size but also to have a more meaningfull output \n",
        "# such as product family due to the items dataset having only product id and not product name\n",
        "train_merged = train_merged.groupby(['date', 'Store', 'ProductFamily'], as_index=False).agg({\n",
        "    'Sales': 'sum',\n",
        "    'OnPromotion': 'sum',\n",
        "})\n",
        "\n",
        "test_merged = test_merged.groupby(['date', 'Store', 'ProductFamily'], as_index=False).agg({\n",
        "    'OnPromotion': 'sum'\n",
        "})\n",
        "\n",
        "products = items.groupby(['ProductFamily'], as_index=False).agg({\n",
        "    'IsPerishable': 'max'\n",
        "})\n",
        "\n",
        "train_merged['OnPromotion'] = train_merged['OnPromotion'].astype('Int64')\n",
        "test_merged['OnPromotion'] = test_merged['OnPromotion'].astype('Int64')"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1749081129806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged['OnPromotion'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "OnPromotion\n0      1450574\n1       174551\n2        79386\n3        45862\n4        31659\n        ...   \n263          1\n591          1\n248          1\n519          1\n425          1\nName: count, Length: 362, dtype: Int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1749081129998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_merged['OnPromotion'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "OnPromotion\n0      15943\n1       2542\n2       1102\n3        648\n10       557\n       ...  \n231        1\n258        1\n213        1\n111        1\n592        1\nName: count, Length: 212, dtype: Int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1749081130284
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure that each store has no missing dates and no missing products since needed for times series model.\n",
        "# if there are missing data, it implies no sales on that date so missing values will be set to 0.\n",
        "product_families = products['ProductFamily'].unique()\n",
        "\n",
        "dates_train = pd.date_range(start='2013-01-01', end='2017-08-15')\n",
        "dates_test = pd.date_range(start='2017-08-16', end='2017-08-31')\n",
        "\n",
        "all_stores = stores['Store'].unique()\n",
        "\n",
        "# Create dataframe having all dates, stores, products combinations\n",
        "df_train = pd.DataFrame(index=(pd.MultiIndex.from_product([dates_train, all_stores, product_families], names=['date', 'Store', 'ProductFamily']))).reset_index()\n",
        "df_test = pd.DataFrame(index=(pd.MultiIndex.from_product([dates_test, all_stores, product_families], names=['date', 'Store', 'ProductFamily']))).reset_index()\n",
        "\n",
        "# Merging with original train dataset to add the missing data\n",
        "train_merged = pd.merge(df_train, train_merged, on=['date', 'Store', 'ProductFamily'], how='left')\n",
        "test_merged = pd.merge(df_test, test_merged, on=['date', 'Store', 'ProductFamily'], how='left')\n",
        "\n",
        "print(train_merged['Sales'].isnull().any())\n",
        "print(train_merged['Sales'].isnull().sum())\n",
        "\n",
        "print(train_merged['OnPromotion'].isnull().any())\n",
        "print(train_merged['OnPromotion'].isnull().sum())\n",
        "\n",
        "print(test_merged['OnPromotion'].isnull().any())\n",
        "print(test_merged['OnPromotion'].isnull().sum())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "True\n946113\nTrue\n946113\nFalse\n0\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1749081130590
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing data with 0\n",
        "train_merged['Sales'] = train_merged['Sales'].fillna(0)\n",
        "\n",
        "train_merged['OnPromotion'] = train_merged['OnPromotion'].fillna(0)\n",
        "test_merged['OnPromotion'] = test_merged['OnPromotion'].fillna(0)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1749081130779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract time features for time-series and seasonality trends\n",
        "train_merged['Year'] = train_merged['date'].dt.year\n",
        "train_merged['Month'] = train_merged['date'].dt.month\n",
        "train_merged['Day']=train_merged['date'].dt.day\n",
        "train_merged['DayOfWeek'] = train_merged['date'].dt.dayofweek\n",
        "\n",
        "test_merged['Year'] = test_merged['date'].dt.year\n",
        "test_merged['Month'] = test_merged['date'].dt.month\n",
        "test_merged['Day']=test_merged['date'].dt.day\n",
        "test_merged['DayOfWeek'] = test_merged['date'].dt.dayofweek"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1749081131028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "              date  Store               ProductFamily    Sales  OnPromotion  \\\n0       2013-01-01      1                  AUTOMOTIVE    0.000            0   \n1       2013-01-01      1                   BABY CARE    0.000            0   \n2       2013-01-01      1                      BEAUTY    0.000            0   \n3       2013-01-01      1                   BEVERAGES    0.000            0   \n4       2013-01-01      1                       BOOKS    0.000            0   \n...            ...    ...                         ...      ...          ...   \n3008011 2017-08-15     54                     POULTRY   59.619            0   \n3008012 2017-08-15     54              PREPARED FOODS   94.000            0   \n3008013 2017-08-15     54                     PRODUCE  915.371           76   \n3008014 2017-08-15     54  SCHOOL AND OFFICE SUPPLIES    0.000            0   \n3008015 2017-08-15     54                     SEAFOOD    3.000            0   \n\n         Year  Month  Day  DayOfWeek  \n0        2013      1    1          1  \n1        2013      1    1          1  \n2        2013      1    1          1  \n3        2013      1    1          1  \n4        2013      1    1          1  \n...       ...    ...  ...        ...  \n3008011  2017      8   15          1  \n3008012  2017      8   15          1  \n3008013  2017      8   15          1  \n3008014  2017      8   15          1  \n3008015  2017      8   15          1  \n\n[3008016 rows x 9 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>Store</th>\n      <th>ProductFamily</th>\n      <th>Sales</th>\n      <th>OnPromotion</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>DayOfWeek</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>AUTOMOTIVE</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>BABY CARE</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>BEAUTY</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>BEVERAGES</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-01-01</td>\n      <td>1</td>\n      <td>BOOKS</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3008011</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>POULTRY</td>\n      <td>59.619</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3008012</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>PREPARED FOODS</td>\n      <td>94.000</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3008013</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>PRODUCE</td>\n      <td>915.371</td>\n      <td>76</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3008014</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>SCHOOL AND OFFICE SUPPLIES</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3008015</th>\n      <td>2017-08-15</td>\n      <td>54</td>\n      <td>SEAFOOD</td>\n      <td>3.000</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3008016 rows  9 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1749081131216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_merged"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "            date  Store               ProductFamily  OnPromotion  Year  Month  \\\n0     2017-08-16      1                  AUTOMOTIVE            0  2017      8   \n1     2017-08-16      1                   BABY CARE            0  2017      8   \n2     2017-08-16      1                      BEAUTY            2  2017      8   \n3     2017-08-16      1                   BEVERAGES           20  2017      8   \n4     2017-08-16      1                       BOOKS            0  2017      8   \n...          ...    ...                         ...          ...   ...    ...   \n28507 2017-08-31     54                     POULTRY            0  2017      8   \n28508 2017-08-31     54              PREPARED FOODS            0  2017      8   \n28509 2017-08-31     54                     PRODUCE            1  2017      8   \n28510 2017-08-31     54  SCHOOL AND OFFICE SUPPLIES            0  2017      8   \n28511 2017-08-31     54                     SEAFOOD            0  2017      8   \n\n       Day  DayOfWeek  \n0       16          2  \n1       16          2  \n2       16          2  \n3       16          2  \n4       16          2  \n...    ...        ...  \n28507   31          3  \n28508   31          3  \n28509   31          3  \n28510   31          3  \n28511   31          3  \n\n[28512 rows x 8 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>Store</th>\n      <th>ProductFamily</th>\n      <th>OnPromotion</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>DayOfWeek</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>AUTOMOTIVE</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BABY CARE</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BEAUTY</td>\n      <td>2</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BEVERAGES</td>\n      <td>20</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-08-16</td>\n      <td>1</td>\n      <td>BOOKS</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28507</th>\n      <td>2017-08-31</td>\n      <td>54</td>\n      <td>POULTRY</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28508</th>\n      <td>2017-08-31</td>\n      <td>54</td>\n      <td>PREPARED FOODS</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28509</th>\n      <td>2017-08-31</td>\n      <td>54</td>\n      <td>PRODUCE</td>\n      <td>1</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28510</th>\n      <td>2017-08-31</td>\n      <td>54</td>\n      <td>SCHOOL AND OFFICE SUPPLIES</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28511</th>\n      <td>2017-08-31</td>\n      <td>54</td>\n      <td>SEAFOOD</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>8</td>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows  8 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1749081131404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the rest of the data \n",
        "# Not merging with transactions since need to forecast test dates transactions\n",
        "# No need to merge with store dataset since model for demand forecasting gonna be trained by store\n",
        "# and essentially the store columns would be identical for all sequence and redundant/unnecessary\n",
        "\n",
        "train_merged = train_merged.merge(products, on=\"ProductFamily\", how=\"left\")\n",
        "test_merged = test_merged.merge(products, on=\"ProductFamily\", how=\"left\")\n",
        "\n",
        "train_merged = train_merged.merge(holidays, on=[\"date\"], how=\"left\")\n",
        "test_merged = test_merged.merge(holidays, on=[\"date\"], how=\"left\")\n",
        "\n",
        "train_merged = train_merged.merge(oil, on=[\"date\"], how=\"left\")\n",
        "test_merged = test_merged.merge(oil, on=[\"date\"], how=\"left\")"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1749081131660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null values from the merge\n",
        "# If is_holiday is NaN it means it is a normal day so fill value with 0\n",
        "train_merged['IsHoliday'] = train_merged['IsHoliday'].fillna(0)\n",
        "test_merged['IsHoliday'] = test_merged['IsHoliday'].fillna(0)\n",
        "\n",
        "# Fill the empty oil_price dates with the previous day,\n",
        "# since no price data for the date, it implies oil price unchanged\n",
        "train_merged[\"OilPrice\"] = train_merged[\"OilPrice\"].ffill()\n",
        "test_merged[\"OilPrice\"] = test_merged[\"OilPrice\"].ffill() "
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1749081131826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"====================================Merged Train Data====================================\")\n",
        "basic_eda(train_merged)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "====================================Merged Train Data====================================\n              date  Store               ProductFamily    Sales  OnPromotion  \\\n0       2013-01-01      1                  AUTOMOTIVE    0.000            0   \n1       2013-01-01      1                   BABY CARE    0.000            0   \n2       2013-01-01      1                      BEAUTY    0.000            0   \n3       2013-01-01      1                   BEVERAGES    0.000            0   \n4       2013-01-01      1                       BOOKS    0.000            0   \n...            ...    ...                         ...      ...          ...   \n3008011 2017-08-15     54                     POULTRY   59.619            0   \n3008012 2017-08-15     54              PREPARED FOODS   94.000            0   \n3008013 2017-08-15     54                     PRODUCE  915.371           76   \n3008014 2017-08-15     54  SCHOOL AND OFFICE SUPPLIES    0.000            0   \n3008015 2017-08-15     54                     SEAFOOD    3.000            0   \n\n         Year  Month  Day  DayOfWeek  IsPerishable  IsHoliday  OilPrice  \n0        2013      1    1          1             0        1.0     93.14  \n1        2013      1    1          1             0        1.0     93.14  \n2        2013      1    1          1             0        1.0     93.14  \n3        2013      1    1          1             0        1.0     93.14  \n4        2013      1    1          1             0        1.0     93.14  \n...       ...    ...  ...        ...           ...        ...       ...  \n3008011  2017      8   15          1             1        1.0     47.57  \n3008012  2017      8   15          1             1        1.0     47.57  \n3008013  2017      8   15          1             1        1.0     47.57  \n3008014  2017      8   15          1             0        1.0     47.57  \n3008015  2017      8   15          1             1        1.0     47.57  \n\n[3008016 rows x 12 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3008016 entries, 0 to 3008015\nData columns (total 12 columns):\n #   Column         Dtype         \n---  ------         -----         \n 0   date           datetime64[ns]\n 1   Store          int64         \n 2   ProductFamily  object        \n 3   Sales          float64       \n 4   OnPromotion    Int64         \n 5   Year           int32         \n 6   Month          int32         \n 7   Day            int32         \n 8   DayOfWeek      int32         \n 9   IsPerishable   int64         \n 10  IsHoliday      float64       \n 11  OilPrice       float64       \ndtypes: Int64(1), datetime64[ns](1), float64(3), int32(4), int64(2), object(1)\nmemory usage: 232.4+ MB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['date', 'Store', 'ProductFamily', 'Sales', 'OnPromotion', 'Year',\n       'Month', 'Day', 'DayOfWeek', 'IsPerishable', 'IsHoliday', 'OilPrice'],\n      dtype='object')\n----------------------------------Data Types-----------------------------------\ndate             datetime64[ns]\nStore                     int64\nProductFamily            object\nSales                   float64\nOnPromotion               Int64\nYear                      int32\nMonth                     int32\nDay                       int32\nDayOfWeek                 int32\nIsPerishable              int64\nIsHoliday               float64\nOilPrice                float64\ndtype: object\n-------------------------------Missing Values----------------------------------\ndate             0\nStore            0\nProductFamily    0\nSales            0\nOnPromotion      0\nYear             0\nMonth            0\nDay              0\nDayOfWeek        0\nIsPerishable     0\nIsHoliday        0\nOilPrice         0\ndtype: int64\n-------------------------------NULL values-------------------------------------\ndate             0\nStore            0\nProductFamily    0\nSales            0\nOnPromotion      0\nYear             0\nMonth            0\nDay              0\nDayOfWeek        0\nIsPerishable     0\nIsHoliday        0\nOilPrice         0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(3008016, 12)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'ProductFamily' unique values:\n['AUTOMOTIVE' 'BABY CARE' 'BEAUTY' 'BEVERAGES' 'BOOKS' 'BREAD/BAKERY'\n 'CELEBRATION' 'CLEANING' 'DAIRY' 'DELI' 'EGGS' 'FROZEN FOODS' 'GROCERY I'\n 'GROCERY II' 'HARDWARE' 'HOME AND KITCHEN I' 'HOME AND KITCHEN II'\n 'HOME APPLIANCES' 'HOME CARE' 'LADIESWEAR' 'LAWN AND GARDEN' 'LINGERIE'\n 'LIQUOR,WINE,BEER' 'MAGAZINES' 'MEATS' 'PERSONAL CARE' 'PET SUPPLIES'\n 'PLAYERS AND ELECTRONICS' 'POULTRY' 'PREPARED FOODS' 'PRODUCE'\n 'SCHOOL AND OFFICE SUPPLIES' 'SEAFOOD']\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1749081132090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA\n",
        "print(\"====================================Merged Test Data====================================\")\n",
        "basic_eda(test_merged)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "====================================Merged Test Data====================================\n            date  Store               ProductFamily  OnPromotion  Year  Month  \\\n0     2017-08-16      1                  AUTOMOTIVE            0  2017      8   \n1     2017-08-16      1                   BABY CARE            0  2017      8   \n2     2017-08-16      1                      BEAUTY            2  2017      8   \n3     2017-08-16      1                   BEVERAGES           20  2017      8   \n4     2017-08-16      1                       BOOKS            0  2017      8   \n...          ...    ...                         ...          ...   ...    ...   \n28507 2017-08-31     54                     POULTRY            0  2017      8   \n28508 2017-08-31     54              PREPARED FOODS            0  2017      8   \n28509 2017-08-31     54                     PRODUCE            1  2017      8   \n28510 2017-08-31     54  SCHOOL AND OFFICE SUPPLIES            0  2017      8   \n28511 2017-08-31     54                     SEAFOOD            0  2017      8   \n\n       Day  DayOfWeek  IsPerishable  IsHoliday  OilPrice  \n0       16          2             0        0.0     46.80  \n1       16          2             0        0.0     46.80  \n2       16          2             0        0.0     46.80  \n3       16          2             0        0.0     46.80  \n4       16          2             0        0.0     46.80  \n...    ...        ...           ...        ...       ...  \n28507   31          3             1        0.0     47.26  \n28508   31          3             1        0.0     47.26  \n28509   31          3             1        0.0     47.26  \n28510   31          3             0        0.0     47.26  \n28511   31          3             1        0.0     47.26  \n\n[28512 rows x 11 columns]\n----------------------------------INFO-----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28512 entries, 0 to 28511\nData columns (total 11 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   date           28512 non-null  datetime64[ns]\n 1   Store          28512 non-null  int64         \n 2   ProductFamily  28512 non-null  object        \n 3   OnPromotion    28512 non-null  Int64         \n 4   Year           28512 non-null  int32         \n 5   Month          28512 non-null  int32         \n 6   Day            28512 non-null  int32         \n 7   DayOfWeek      28512 non-null  int32         \n 8   IsPerishable   28512 non-null  int64         \n 9   IsHoliday      28512 non-null  float64       \n 10  OilPrice       28512 non-null  float64       \ndtypes: Int64(1), datetime64[ns](1), float64(2), int32(4), int64(2), object(1)\nmemory usage: 2.0+ MB\nNone\n----------------------------------Columns--------------------------------------\nIndex(['date', 'Store', 'ProductFamily', 'OnPromotion', 'Year', 'Month', 'Day',\n       'DayOfWeek', 'IsPerishable', 'IsHoliday', 'OilPrice'],\n      dtype='object')\n----------------------------------Data Types-----------------------------------\ndate             datetime64[ns]\nStore                     int64\nProductFamily            object\nOnPromotion               Int64\nYear                      int32\nMonth                     int32\nDay                       int32\nDayOfWeek                 int32\nIsPerishable              int64\nIsHoliday               float64\nOilPrice                float64\ndtype: object\n-------------------------------Missing Values----------------------------------\ndate             0\nStore            0\nProductFamily    0\nOnPromotion      0\nYear             0\nMonth            0\nDay              0\nDayOfWeek        0\nIsPerishable     0\nIsHoliday        0\nOilPrice         0\ndtype: int64\n-------------------------------NULL values-------------------------------------\ndate             0\nStore            0\nProductFamily    0\nOnPromotion      0\nYear             0\nMonth            0\nDay              0\nDayOfWeek        0\nIsPerishable     0\nIsHoliday        0\nOilPrice         0\ndtype: int64\n------------------------------Shape Of Data------------------------------------\n(28512, 11)\n-------------------------Unique values per categorical column-------------------\n\nColumn 'ProductFamily' unique values:\n['AUTOMOTIVE' 'BABY CARE' 'BEAUTY' 'BEVERAGES' 'BOOKS' 'BREAD/BAKERY'\n 'CELEBRATION' 'CLEANING' 'DAIRY' 'DELI' 'EGGS' 'FROZEN FOODS' 'GROCERY I'\n 'GROCERY II' 'HARDWARE' 'HOME AND KITCHEN I' 'HOME AND KITCHEN II'\n 'HOME APPLIANCES' 'HOME CARE' 'LADIESWEAR' 'LAWN AND GARDEN' 'LINGERIE'\n 'LIQUOR,WINE,BEER' 'MAGAZINES' 'MEATS' 'PERSONAL CARE' 'PET SUPPLIES'\n 'PLAYERS AND ELECTRONICS' 'POULTRY' 'PREPARED FOODS' 'PRODUCE'\n 'SCHOOL AND OFFICE SUPPLIES' 'SEAFOOD']\n=============================================================================== \n\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1749081132247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save new datasets to files\n",
        "stores.to_csv('stores_updated.csv', index=False)\n",
        "holidays.to_csv('holidays_updated.csv', index=False)\n",
        "products.to_csv('items_updated.csv', index=False)\n",
        "train_merged.to_csv('train_merged_0.csv', index=False)\n",
        "test_merged.to_csv('test_merged_0.csv', index=False)\n",
        "oil.to_csv('oil_updated.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1749081145005
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}